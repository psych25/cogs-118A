{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7aef021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde50101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset#1\n",
    "file_path = \"/Users/maissanafisa/Desktop/data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f98e59cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Marital status  Application mode  Application order  Course  \\\n",
       " 0               1                17                  5     171   \n",
       " 1               1                15                  1    9254   \n",
       " 2               1                 1                  5    9070   \n",
       " 3               1                17                  2    9773   \n",
       " 4               2                39                  1    8014   \n",
       " \n",
       "    Daytime/evening attendance\\t  Previous qualification  \\\n",
       " 0                             1                       1   \n",
       " 1                             1                       1   \n",
       " 2                             1                       1   \n",
       " 3                             1                       1   \n",
       " 4                             0                       1   \n",
       " \n",
       "    Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       " 0                           122.0            1                      19   \n",
       " 1                           160.0            1                       1   \n",
       " 2                           122.0            1                      37   \n",
       " 3                           122.0            1                      38   \n",
       " 4                           100.0            1                      37   \n",
       " \n",
       "    Father's qualification  ...  \\\n",
       " 0                      12  ...   \n",
       " 1                       3  ...   \n",
       " 2                      37  ...   \n",
       " 3                      37  ...   \n",
       " 4                      38  ...   \n",
       " \n",
       "    Curricular units 1st sem (without evaluations)  \\\n",
       " 0                                               0   \n",
       " 1                                               0   \n",
       " 2                                               0   \n",
       " 3                                               0   \n",
       " 4                                               0   \n",
       " \n",
       "    Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       " 0                                    0                                    0   \n",
       " 1                                    0                                    6   \n",
       " 2                                    0                                    6   \n",
       " 3                                    0                                    6   \n",
       " 4                                    0                                    6   \n",
       " \n",
       "    Curricular units 2nd sem (evaluations)  \\\n",
       " 0                                       0   \n",
       " 1                                       6   \n",
       " 2                                       0   \n",
       " 3                                      10   \n",
       " 4                                       6   \n",
       " \n",
       "    Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       " 0                                    0                          0.000000   \n",
       " 1                                    6                         13.666667   \n",
       " 2                                    0                          0.000000   \n",
       " 3                                    5                         12.400000   \n",
       " 4                                    6                         13.000000   \n",
       " \n",
       "    Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       " 0                                               0               10.8   \n",
       " 1                                               0               13.9   \n",
       " 2                                               0               10.8   \n",
       " 3                                               0                9.4   \n",
       " 4                                               0               13.9   \n",
       " \n",
       "    Inflation rate   GDP  \n",
       " 0             1.4  1.74  \n",
       " 1            -0.3  0.79  \n",
       " 2             1.4  1.74  \n",
       " 3            -0.8 -3.12  \n",
       " 4            -0.3  0.79  \n",
       " \n",
       " [5 rows x 36 columns],\n",
       " 0    0\n",
       " 1    2\n",
       " 2    0\n",
       " 3    2\n",
       " 4    2\n",
       " Name: Target, dtype: int64,\n",
       " 'Missing values in features: 0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Graduate is encoded as 1, and Dropout as 0\n",
    "label_encoder = LabelEncoder()\n",
    "data['Target'] = label_encoder.fit_transform(data['Target'])  \n",
    "\n",
    "X = data.drop(columns=['Target'])\n",
    "y = data['Target']\n",
    "\n",
    "missing_values = X.isnull().sum().sum()\n",
    "\n",
    "X.head(), y.head(), f\"Missing values in features: {missing_values}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cf03a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sizes = [0.2, 0.5, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "592b8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Test size: 0.2 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                        |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:---------------------------------------|\n",
      "| Random Forest |           0.9994 |                 0.768 |           0.774 | {'max_depth': 20, 'n_estimators': 200} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.5 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                          |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:-----------------------------------------|\n",
      "| Random Forest |                1 |                0.7731 |          0.7685 | {'max_depth': None, 'n_estimators': 300} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.8 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                        |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:---------------------------------------|\n",
      "| Random Forest |           0.9717 |                0.7568 |          0.7599 | {'max_depth': 10, 'n_estimators': 100} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20,50]\n",
    "}\n",
    "\n",
    "def hyperparameter_tuning_rf(X_train, y_train):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=42),\n",
    "        param_grid=param_grid_rf,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.cv_results_\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "partition_results_rf = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params, cv_results = hyperparameter_tuning_rf(X_train, y_train)\n",
    "    preds_train = tuned_clf.predict(X_train)\n",
    "    preds_test = tuned_clf.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    test_accuracy = accuracy_score(y_test, preds_test)\n",
    "    validation_accuracy = max(cv_results['mean_test_score'])  \n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Random Forest',\n",
    "        'Train Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(validation_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_rf[f\"Random Forest - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Random Forest results\n",
    "for partition, df in partition_results_rf.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77160b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Test size: 0.2 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                                 |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:------------------------------------------------|\n",
      "| Logistic Regression |           0.7765 |                0.7624 |          0.7627 | {'model__C': 100, 'model__solver': 'liblinear'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.5 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                               |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:----------------------------------------------|\n",
      "| Logistic Regression |           0.7749 |                0.7572 |          0.7654 | {'model__C': 1, 'model__solver': 'liblinear'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.8 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                                |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:-----------------------------------------------|\n",
      "| Logistic Regression |            0.802 |                0.7613 |          0.7523 | {'model__C': 10, 'model__solver': 'liblinear'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "\n",
    "# Hyperparameter grid for Logistic Regression\n",
    "partition_results = {}\n",
    "test_sizes = [0.2, 0.5, 0.8]\n",
    "param_grid_lr = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function\n",
    "def hyperparameter_tuning_lr(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(max_iter=2000, random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_lr,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.cv_results_\n",
    "\n",
    "# Evaluate Logistic Regression Classifier\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params, cv_results = hyperparameter_tuning_lr(X_train, y_train)\n",
    "    preds_train = tuned_clf.predict(X_train)\n",
    "    preds_test = tuned_clf.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    validation_accuracy = max(cv_results['mean_test_score'])\n",
    "    test_accuracy = accuracy_score(y_test, preds_test)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Logistic Regression',\n",
    "        'Train Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(validation_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results[f\"Logistic Regression - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Logistic Regression results\n",
    "for partition, df in partition_results.items():\n",
    "    if \"Logistic Regression\" in partition:\n",
    "        print(f\"{partition} Results:\")\n",
    "        print(df.to_markdown(index=False))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee15b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Test size: 0.2 Results:\n",
      "| Classifier             |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-----------------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| Support Vector Machine |              0.7723 |                0.7626 |          0.7537 |      0.7466 |   0.7537 |     0.7452 | {'model__C': 100, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.5 Results:\n",
      "| Classifier             |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-----------------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| Support Vector Machine |              0.7717 |                0.7559 |          0.7654 |      0.7567 |   0.7654 |     0.7549 | {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.8 Results:\n",
      "| Classifier             |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-----------------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| Support Vector Machine |              0.8077 |                0.7568 |          0.7494 |      0.7318 |   0.7494 |     0.7341 | {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'model__C': [0.1, 1, 10, 100],\n",
    "    'model__kernel': ['linear', 'rbf'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for SVM\n",
    "def hyperparameter_tuning_svm(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_svm,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate SVM Classifier\n",
    "partition_results_svm = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_svm(X_train, y_train)\n",
    "\n",
    "    # Training Accuracy\n",
    "    train_accuracy = tuned_clf.score(X_train, y_train)\n",
    "\n",
    "    # Validation Accuracy (Cross-Validation)\n",
    "    val_accuracy = cross_val_score(tuned_clf, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    # Test Accuracy\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Support Vector Machine',\n",
    "        'Training Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(val_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_svm[f\"SVM - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display SVM results\n",
    "for partition, df in partition_results_svm.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e41b478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Test size: 0.2 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |               0.683 |                0.6734 |          0.6599 |      0.6347 |   0.6599 |     0.6432 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.5 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |              0.6849 |                0.6763 |          0.6759 |      0.6564 |   0.6759 |     0.6617 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.8 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |              0.6957 |                0.6617 |          0.6853 |      0.6904 |   0.6853 |     0.6849 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Training Accuracy\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "\n",
    "    # Validation Accuracy (Cross-Validation)\n",
    "    val_accuracy = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    # Test Accuracy\n",
    "    preds = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Naive Bayes',\n",
    "        'Training Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(val_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4)\n",
    "    }]\n",
    "\n",
    "    return results\n",
    "\n",
    "# Evaluate Naive Bayes Classifier\n",
    "partition_results_nb = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    results = evaluate_naive_bayes(X_train, X_test, y_train, y_test)\n",
    "    partition_results_nb[f\"Naive Bayes - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Naive Bayes results\n",
    "for partition, df in partition_results_nb.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17fcb0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Test size: 0.2 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                        |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:-----------------------------------------------------------------------|\n",
      "| KNN          |              0.7689 |                0.7172 |          0.7175 |      0.7037 |   0.7175 |     0.6987 | {'model__n_neighbors': 10, 'model__p': 1, 'model__weights': 'uniform'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.5 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                        |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:-----------------------------------------------------------------------|\n",
      "| KNN          |               0.764 |                 0.708 |          0.7129 |      0.6989 |   0.7129 |      0.691 | {'model__n_neighbors': 10, 'model__p': 1, 'model__weights': 'uniform'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.8 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                        |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:-----------------------------------------------------------------------|\n",
      "| KNN          |                   1 |                0.7025 |          0.6912 |      0.6856 |   0.6912 |      0.671 | {'model__n_neighbors': 7, 'model__p': 1, 'model__weights': 'distance'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'model__n_neighbors': [3, 5, 7, 10],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__p': [1, 2]  # Minkowski p=1 (Manhattan), p=2 (Euclidean)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for KNN\n",
    "def hyperparameter_tuning_knn(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_knn,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate KNN Classifier\n",
    "partition_results_knn = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_knn(X_train, y_train)\n",
    "\n",
    "    # Training Accuracy\n",
    "    train_accuracy = tuned_clf.score(X_train, y_train)\n",
    "\n",
    "    # Validation Accuracy (Cross-Validation)\n",
    "    val_accuracy = cross_val_score(tuned_clf, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    # Test Accuracy\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'KNN',\n",
    "        'Training Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(val_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_knn[f\"KNN - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display KNN results\n",
    "for partition, df in partition_results_knn.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b680b273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset 2\n",
    "file_path = \"/Users/maissanafisa/Downloads/online_shoppers_intention.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd82cb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Administrative  Administrative_Duration  Informational  \\\n",
       " 0               0                      0.0              0   \n",
       " 1               0                      0.0              0   \n",
       " 2               0                      0.0              0   \n",
       " 3               0                      0.0              0   \n",
       " 4               0                      0.0              0   \n",
       " \n",
       "    Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       " 0                     0.0               1                 0.000000   \n",
       " 1                     0.0               2                64.000000   \n",
       " 2                     0.0               1                 0.000000   \n",
       " 3                     0.0               2                 2.666667   \n",
       " 4                     0.0              10               627.500000   \n",
       " \n",
       "    BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       " 0         0.20       0.20         0.0         0.0      2                 1   \n",
       " 1         0.00       0.10         0.0         0.0      2                 2   \n",
       " 2         0.20       0.20         0.0         0.0      2                 4   \n",
       " 3         0.05       0.14         0.0         0.0      2                 3   \n",
       " 4         0.02       0.05         0.0         0.0      2                 3   \n",
       " \n",
       "    Browser  Region  TrafficType  VisitorType  Weekend  \n",
       " 0        1       1            1            2        0  \n",
       " 1        2       1            2            2        0  \n",
       " 2        1       9            3            2        0  \n",
       " 3        2       2            4            2        0  \n",
       " 4        3       1            4            2        1  ,\n",
       " 0    0\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " Name: Revenue, dtype: int64,\n",
       " 'Missing values in features: 0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode 'VisitorType' (e.g., Returning_Visitor -> 0, Others -> 1)\n",
    "data['VisitorType'] = label_encoder.fit_transform(data['VisitorType'])\n",
    "\n",
    "# Convert 'Weekend' and 'Revenue' from boolean to integer (True -> 1, False -> 0)\n",
    "data['Weekend'] = data['Weekend'].astype(int)\n",
    "data['Revenue'] = data['Revenue'].astype(int)\n",
    "data['Month'] = label_encoder.fit_transform(data['Month'])\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = data.drop(columns=['Revenue'])  # Features\n",
    "y = data['Revenue']  # Target (binary: 0 for no purchase, 1 for purchase)\n",
    "\n",
    "missing_values = X.isnull().sum().sum()\n",
    "X.head(), y.head(), f\"Missing values in features: {missing_values}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9bd7033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Test size: 0.2 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                          |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:-----------------------------------------|\n",
      "| Random Forest |                1 |                 0.905 |          0.8994 | {'max_depth': None, 'n_estimators': 100} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.5 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                          |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:-----------------------------------------|\n",
      "| Random Forest |                1 |                0.9067 |          0.9019 | {'max_depth': None, 'n_estimators': 200} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.8 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                        |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:---------------------------------------|\n",
      "| Random Forest |           0.9781 |                0.9055 |          0.9014 | {'max_depth': 10, 'n_estimators': 100} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20,50]\n",
    "}\n",
    "\n",
    "def hyperparameter_tuning_rf(X_train, y_train):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=42),\n",
    "        param_grid=param_grid_rf,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.cv_results_\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "partition_results_rf = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params, cv_results = hyperparameter_tuning_rf(X_train, y_train)\n",
    "    preds_train = tuned_clf.predict(X_train)\n",
    "    preds_test = tuned_clf.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    test_accuracy = accuracy_score(y_test, preds_test)\n",
    "    validation_accuracy = max(cv_results['mean_test_score'])  \n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Random Forest',\n",
    "        'Train Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(validation_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_rf[f\"Random Forest - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Random Forest results\n",
    "for partition, df in partition_results_rf.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a34269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Test size: 0.2 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                           |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:------------------------------------------|\n",
      "| Logistic Regression |           0.8854 |                0.8849 |          0.8832 | {'model__C': 1, 'model__solver': 'lbfgs'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.5 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                           |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:------------------------------------------|\n",
      "| Logistic Regression |           0.8868 |                0.8863 |          0.8822 | {'model__C': 1, 'model__solver': 'lbfgs'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.8 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                               |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:----------------------------------------------|\n",
      "| Logistic Regression |           0.8897 |                0.8881 |          0.8838 | {'model__C': 1, 'model__solver': 'liblinear'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "\n",
    "# Hyperparameter grid for Logistic Regression\n",
    "partition_results = {}\n",
    "test_sizes = [0.2, 0.5, 0.8]\n",
    "param_grid_lr = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function\n",
    "def hyperparameter_tuning_lr(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(max_iter=2000, random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_lr,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.cv_results_\n",
    "\n",
    "# Evaluate Logistic Regression Classifier\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params, cv_results = hyperparameter_tuning_lr(X_train, y_train)\n",
    "    preds_train = tuned_clf.predict(X_train)\n",
    "    preds_test = tuned_clf.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    validation_accuracy = max(cv_results['mean_test_score'])\n",
    "    test_accuracy = accuracy_score(y_test, preds_test)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Logistic Regression',\n",
    "        'Train Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(validation_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results[f\"Logistic Regression - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Logistic Regression results\n",
    "for partition, df in partition_results.items():\n",
    "    if \"Logistic Regression\" in partition:\n",
    "        print(f\"{partition} Results:\")\n",
    "        print(df.to_markdown(index=False))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "555cb0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Test size: 0.2 Results:\n",
      "| Classifier             |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                  |\n",
      "|:-----------------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:-----------------------------------------------------------------|\n",
      "| Support Vector Machine |              0.9074 |                 0.892 |          0.8844 |      0.8727 |   0.8844 |     0.8724 | {'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'rbf'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.5 Results:\n",
      "| Classifier             |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                  |\n",
      "|:-----------------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:-----------------------------------------------------------------|\n",
      "| Support Vector Machine |              0.9072 |                0.8931 |            0.89 |        0.88 |     0.89 |     0.8776 | {'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'rbf'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.8 Results:\n",
      "| Classifier             |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-----------------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| Support Vector Machine |              0.8909 |                0.8909 |          0.8852 |      0.8737 |   0.8852 |     0.8716 | {'model__C': 100, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'model__C': [0.1, 1, 10, 100],\n",
    "    'model__kernel': ['linear', 'rbf'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for SVM\n",
    "def hyperparameter_tuning_svm(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_svm,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate SVM Classifier\n",
    "partition_results_svm = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_svm(X_train, y_train)\n",
    "\n",
    "    # Training Accuracy\n",
    "    train_accuracy = tuned_clf.score(X_train, y_train)\n",
    "\n",
    "    # Validation Accuracy (Cross-Validation)\n",
    "    val_accuracy = cross_val_score(tuned_clf, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    # Test Accuracy\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Support Vector Machine',\n",
    "        'Training Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(val_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_svm[f\"SVM - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display SVM results\n",
    "for partition, df in partition_results_svm.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c890d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Test size: 0.2 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |              0.8479 |                0.8483 |          0.8439 |      0.8474 |   0.8439 |     0.8456 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.5 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |              0.8509 |                0.8503 |          0.8503 |      0.8546 |   0.8503 |     0.8523 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.8 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |              0.8451 |                0.8467 |           0.843 |      0.8502 |    0.843 |     0.8463 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Training Accuracy\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "\n",
    "    # Validation Accuracy (Cross-Validation)\n",
    "    val_accuracy = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    # Test Accuracy\n",
    "    preds = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Naive Bayes',\n",
    "        'Training Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(val_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4)\n",
    "    }]\n",
    "\n",
    "    return results\n",
    "\n",
    "# Evaluate Naive Bayes Classifier\n",
    "partition_results_nb = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    results = evaluate_naive_bayes(X_train, X_test, y_train, y_test)\n",
    "    partition_results_nb[f\"Naive Bayes - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Naive Bayes results\n",
    "for partition, df in partition_results_nb.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d6ed42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Test size: 0.2 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| KNN          |              0.8988 |                0.8807 |          0.8783 |      0.8644 |   0.8783 |     0.8626 | {'model__n_neighbors': 7, 'model__p': 2, 'model__weights': 'uniform'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.5 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                         |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:------------------------------------------------------------------------|\n",
      "| KNN          |                   1 |                0.8767 |          0.8775 |      0.8638 |   0.8775 |     0.8583 | {'model__n_neighbors': 10, 'model__p': 2, 'model__weights': 'distance'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.8 Results:\n",
      "| Classifier   |   Training Accuracy |   Validation Accuracy |   Test Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                         |\n",
      "|:-------------|--------------------:|----------------------:|----------------:|------------:|---------:|-----------:|:------------------------------------------------------------------------|\n",
      "| KNN          |                   1 |                0.8751 |          0.8722 |      0.8572 |   0.8722 |     0.8474 | {'model__n_neighbors': 10, 'model__p': 2, 'model__weights': 'distance'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'model__n_neighbors': [3, 5, 7, 10],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__p': [1, 2]  # Minkowski p=1 (Manhattan), p=2 (Euclidean)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for KNN\n",
    "def hyperparameter_tuning_knn(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_knn,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate KNN Classifier\n",
    "partition_results_knn = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_knn(X_train, y_train)\n",
    "\n",
    "    # Training Accuracy\n",
    "    train_accuracy = tuned_clf.score(X_train, y_train)\n",
    "\n",
    "    # Validation Accuracy (Cross-Validation)\n",
    "    val_accuracy = cross_val_score(tuned_clf, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    # Test Accuracy\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'KNN',\n",
    "        'Training Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(val_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_knn[f\"KNN - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display KNN results\n",
    "for partition, df in partition_results_knn.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "606b4637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>BS</th>\n",
       "      <th>BodyTemp</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>RiskLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>13.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>140</td>\n",
       "      <td>85</td>\n",
       "      <td>7.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>70</td>\n",
       "      <td>high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>6.1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76</td>\n",
       "      <td>low risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
       "0   25         130           80  15.0      98.0         86  high risk\n",
       "1   35         140           90  13.0      98.0         70  high risk\n",
       "2   29          90           70   8.0     100.0         80  high risk\n",
       "3   30         140           85   7.0      98.0         70  high risk\n",
       "4   35         120           60   6.1      98.0         76   low risk"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset 3\n",
    "file_path = \"/Users/maissanafisa/Downloads/Maternal Health Risk Data Set.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06e65ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate\n",
      "0   25         130           80  15.0      98.0         86\n",
      "1   35         140           90  13.0      98.0         70\n",
      "2   29          90           70   8.0     100.0         80\n",
      "3   30         140           85   7.0      98.0         70\n",
      "4   35         120           60   6.1      98.0         76\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: RiskLevel, dtype: int64\n",
      "Missing values in features: 0\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['RiskLevel'] = label_encoder.fit_transform(data['RiskLevel'])  # \"high risk\" -> 0, \"low risk\" -> 1\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = data.drop(columns=['RiskLevel'])  \n",
    "y = data['RiskLevel'] \n",
    "\n",
    "missing_values = X.isnull().sum().sum()\n",
    "\n",
    "print(X.head())  \n",
    "print(y.head())  \n",
    "print(f\"Missing values in features: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ad3c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Test size: 0.2 Results:\n",
      "| Classifier    |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                          |\n",
      "|:--------------|-----------:|------------:|---------:|-----------:|:-----------------------------------------|\n",
      "| Random Forest |     0.8621 |      0.8697 |   0.8621 |     0.8634 | {'max_depth': None, 'n_estimators': 200} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.5 Results:\n",
      "| Classifier    |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                        |\n",
      "|:--------------|-----------:|------------:|---------:|-----------:|:---------------------------------------|\n",
      "| Random Forest |     0.7633 |      0.7668 |   0.7633 |     0.7559 | {'max_depth': 10, 'n_estimators': 300} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.8 Results:\n",
      "| Classifier    |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                          |\n",
      "|:--------------|-----------:|------------:|---------:|-----------:|:-----------------------------------------|\n",
      "| Random Forest |     0.7241 |      0.7193 |   0.7241 |     0.7188 | {'max_depth': None, 'n_estimators': 100} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for Random Forest\n",
    "def hyperparameter_tuning_rf(X_train, y_train):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=42),\n",
    "        param_grid=param_grid_rf,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "partition_results_rf = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_rf(X_train, y_train)\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Random Forest',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_rf[f\"Random Forest - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Random Forest results\n",
    "for partition, df in partition_results_rf.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2d39570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Test size: 0.2 Results:\n",
      "| Classifier          |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                  |\n",
      "|:--------------------|-----------:|------------:|---------:|-----------:|:-------------------------------------------------|\n",
      "| Logistic Regression |      0.665 |      0.6874 |    0.665 |     0.6336 | {'model__C': 0.01, 'model__solver': 'liblinear'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.5 Results:\n",
      "| Classifier          |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                 |\n",
      "|:--------------------|-----------:|------------:|---------:|-----------:|:------------------------------------------------|\n",
      "| Logistic Regression |      0.641 |      0.6361 |    0.641 |     0.6151 | {'model__C': 0.1, 'model__solver': 'liblinear'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.8 Results:\n",
      "| Classifier          |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                             |\n",
      "|:--------------------|-----------:|------------:|---------:|-----------:|:--------------------------------------------|\n",
      "| Logistic Regression |     0.6121 |      0.6158 |   0.6121 |     0.6018 | {'model__C': 0.1, 'model__solver': 'lbfgs'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'model__C': [0.01, 0.1, 1, 10],\n",
    "    'model__solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for Logistic Regression\n",
    "def hyperparameter_tuning_lr(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(max_iter=2000, random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_lr,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate Logistic Regression Classifier\n",
    "partition_results_lr = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_lr(X_train, y_train)\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Logistic Regression',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_lr[f\"Logistic Regression - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Logistic Regression results\n",
    "for partition, df in partition_results_lr.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d7b6412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Test size: 0.2 Results:\n",
      "| Classifier             |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                    |\n",
      "|:-----------------------|-----------:|------------:|---------:|-----------:|:-------------------------------------------------------------------|\n",
      "| Support Vector Machine |     0.7389 |       0.747 |   0.7389 |     0.7379 | {'model__C': 100, 'model__gamma': 'scale', 'model__kernel': 'rbf'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.5 Results:\n",
      "| Classifier             |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                    |\n",
      "|:-----------------------|-----------:|------------:|---------:|-----------:|:-------------------------------------------------------------------|\n",
      "| Support Vector Machine |     0.6765 |      0.6692 |   0.6765 |     0.6691 | {'model__C': 100, 'model__gamma': 'scale', 'model__kernel': 'rbf'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.8 Results:\n",
      "| Classifier             |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                     |\n",
      "|:-----------------------|-----------:|------------:|---------:|-----------:|:--------------------------------------------------------------------|\n",
      "| Support Vector Machine |     0.6367 |      0.6385 |   0.6367 |     0.6276 | {'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'model__C': [0.1, 1, 10, 100],\n",
    "    'model__kernel': ['linear', 'rbf'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for SVM\n",
    "def hyperparameter_tuning_svm(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_svm,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate SVM Classifier\n",
    "partition_results_svm = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_svm(X_train, y_train)\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Support Vector Machine',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_svm[f\"SVM - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display SVM results\n",
    "for partition, df in partition_results_svm.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "273cc62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Test size: 0.2 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |     0.6158 |       0.601 |   0.6158 |      0.575 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.5 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |     0.6095 |      0.5935 |   0.6095 |     0.5598 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.8 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |     0.5911 |      0.5778 |   0.5911 |     0.5634 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Naive Bayes',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4)\n",
    "    }]\n",
    "\n",
    "    return results\n",
    "\n",
    "# Evaluate Naive Bayes Classifier\n",
    "partition_results_nb = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    results = evaluate_naive_bayes(X_train, X_test, y_train, y_test)\n",
    "    partition_results_nb[f\"Naive Bayes - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Naive Bayes results\n",
    "for partition, df in partition_results_nb.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b77d1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Test size: 0.2 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                         |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|:------------------------------------------------------------------------|\n",
      "| KNN          |     0.8079 |      0.8144 |   0.8079 |     0.8095 | {'model__n_neighbors': 10, 'model__p': 2, 'model__weights': 'distance'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.5 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                         |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|:------------------------------------------------------------------------|\n",
      "| KNN          |     0.7712 |      0.7759 |   0.7712 |     0.7708 | {'model__n_neighbors': 10, 'model__p': 1, 'model__weights': 'distance'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.8 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                         |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|:------------------------------------------------------------------------|\n",
      "| KNN          |     0.6601 |      0.6619 |   0.6601 |     0.6563 | {'model__n_neighbors': 10, 'model__p': 2, 'model__weights': 'distance'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'model__n_neighbors': [3, 5, 7, 10],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__p': [1, 2]  # Minkowski p=1 (Manhattan), p=2 (Euclidean)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for KNN\n",
    "def hyperparameter_tuning_knn(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_knn,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate KNN Classifier\n",
    "partition_results_knn = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_knn(X_train, y_train)\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'KNN',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_knn[f\"KNN - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display KNN results\n",
    "for partition, df in partition_results_knn.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a0cde68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/Users/maissanafisa/Desktop/ai4i2020.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea919757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Encode 'Type' column\n",
    "    data['Type'] = label_encoder.fit_transform(data['Type'])\n",
    "    \n",
    "    # Encode 'Product ID' column\n",
    "    data['Product ID'] = label_encoder.fit_transform(data['Product ID'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "883a926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in features: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   UDI  Product ID  Type  Air temperature [K]  Process temperature [K]  \\\n",
       " 0    1        7003     2                298.1                    308.6   \n",
       " 1    2        1003     1                298.2                    308.7   \n",
       " 2    3        1004     1                298.1                    308.5   \n",
       " 3    4        1005     1                298.2                    308.6   \n",
       " 4    5        1006     1                298.2                    308.7   \n",
       " \n",
       "    Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  TWF  HDF  PWF  OSF  \\\n",
       " 0                    1551         42.8                0    0    0    0    0   \n",
       " 1                    1408         46.3                3    0    0    0    0   \n",
       " 2                    1498         49.4                5    0    0    0    0   \n",
       " 3                    1433         39.5                7    0    0    0    0   \n",
       " 4                    1408         40.0                9    0    0    0    0   \n",
       " \n",
       "    RNF  \n",
       " 0    0  \n",
       " 1    0  \n",
       " 2    0  \n",
       " 3    0  \n",
       " 4    0  ,\n",
       " 0    0\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " Name: Machine failure, dtype: int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocess_data(data)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop(columns=['Machine failure'])  # Target is 'Machine failure'\n",
    "y = data['Machine failure']\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = X.isnull().sum().sum()\n",
    "print(f\"Missing values in features: {missing_values}\")\n",
    "\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "707e14ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Test size: 0.2 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                          |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:-----------------------------------------|\n",
      "| Random Forest |                1 |                0.9991 |           0.999 | {'max_depth': None, 'n_estimators': 100} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.5 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                          |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:-----------------------------------------|\n",
      "| Random Forest |                1 |                 0.999 |          0.9992 | {'max_depth': None, 'n_estimators': 100} |\n",
      "\n",
      "\n",
      "Random Forest - Test size: 0.8 Results:\n",
      "| Classifier    |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                          |\n",
      "|:--------------|-----------------:|----------------------:|----------------:|:-----------------------------------------|\n",
      "| Random Forest |                1 |                0.9995 |           0.999 | {'max_depth': None, 'n_estimators': 100} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Random Forest Classifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20,50]\n",
    "}\n",
    "\n",
    "def hyperparameter_tuning_rf(X_train, y_train):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=42),\n",
    "        param_grid=param_grid_rf,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.cv_results_\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "partition_results_rf = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params, cv_results = hyperparameter_tuning_rf(X_train, y_train)\n",
    "    preds_train = tuned_clf.predict(X_train)\n",
    "    preds_test = tuned_clf.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    test_accuracy = accuracy_score(y_test, preds_test)\n",
    "    validation_accuracy = max(cv_results['mean_test_score'])  \n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Random Forest',\n",
    "        'Train Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(validation_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_rf[f\"Random Forest - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Random Forest results\n",
    "for partition, df in partition_results_rf.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85297c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Test size: 0.2 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                              |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:---------------------------------------------|\n",
      "| Logistic Regression |           0.9991 |                0.9991 |           0.999 | {'model__C': 0.01, 'model__solver': 'lbfgs'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.5 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                              |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:---------------------------------------------|\n",
      "| Logistic Regression |            0.999 |                 0.999 |          0.9992 | {'model__C': 0.01, 'model__solver': 'lbfgs'} |\n",
      "\n",
      "\n",
      "Logistic Regression - Test size: 0.8 Results:\n",
      "| Classifier          |   Train Accuracy |   Validation Accuracy |   Test Accuracy | Best Parameters                             |\n",
      "|:--------------------|-----------------:|----------------------:|----------------:|:--------------------------------------------|\n",
      "| Logistic Regression |           0.9995 |                0.9995 |           0.999 | {'model__C': 0.1, 'model__solver': 'lbfgs'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "\n",
    "# Hyperparameter grid for Logistic Regression\n",
    "partition_results = {}\n",
    "test_sizes = [0.2, 0.5, 0.8]\n",
    "param_grid_lr = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function\n",
    "def hyperparameter_tuning_lr(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(max_iter=10000, random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_lr,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.cv_results_\n",
    "\n",
    "# Evaluate Logistic Regression Classifier\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params, cv_results = hyperparameter_tuning_lr(X_train, y_train)\n",
    "    preds_train = tuned_clf.predict(X_train)\n",
    "    preds_test = tuned_clf.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    validation_accuracy = max(cv_results['mean_test_score'])\n",
    "    test_accuracy = accuracy_score(y_test, preds_test)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Logistic Regression',\n",
    "        'Train Accuracy': round(train_accuracy, 4),\n",
    "        'Validation Accuracy': round(validation_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results[f\"Logistic Regression - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Logistic Regression results\n",
    "for partition, df in partition_results.items():\n",
    "    if \"Logistic Regression\" in partition:\n",
    "        print(f\"{partition} Results:\")\n",
    "        print(df.to_markdown(index=False))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7f1509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Test size: 0.2 Results:\n",
      "| Classifier             |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-----------------------|-----------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| Support Vector Machine |      0.999 |       0.999 |    0.999 |      0.999 | {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.5 Results:\n",
      "| Classifier             |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-----------------------|-----------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| Support Vector Machine |     0.9992 |      0.9992 |   0.9992 |     0.9992 | {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n",
      "SVM - Test size: 0.8 Results:\n",
      "| Classifier             |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-----------------------|-----------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| Support Vector Machine |      0.999 |       0.999 |    0.999 |      0.999 | {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'model__C': [0.1, 1, 10, 100],\n",
    "    'model__kernel': ['linear', 'rbf'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for SVM\n",
    "def hyperparameter_tuning_svm(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_svm,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate SVM Classifier\n",
    "partition_results_svm = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_svm(X_train, y_train)\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Support Vector Machine',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_svm[f\"SVM - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display SVM results\n",
    "for partition, df in partition_results_svm.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "298b88d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Test size: 0.2 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |      0.998 |       0.998 |    0.998 |      0.998 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.5 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |      0.996 |      0.9962 |    0.996 |     0.9961 |\n",
      "\n",
      "\n",
      "Naive Bayes - Test size: 0.8 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|\n",
      "| Naive Bayes  |     0.9961 |      0.9963 |   0.9961 |     0.9962 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'Naive Bayes',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4)\n",
    "    }]\n",
    "\n",
    "    return results\n",
    "\n",
    "# Evaluate Naive Bayes Classifier\n",
    "partition_results_nb = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    results = evaluate_naive_bayes(X_train, X_test, y_train, y_test)\n",
    "    partition_results_nb[f\"Naive Bayes - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display Naive Bayes results\n",
    "for partition, df in partition_results_nb.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6521673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Test size: 0.2 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| KNN          |      0.999 |       0.999 |    0.999 |      0.999 | {'model__n_neighbors': 3, 'model__p': 1, 'model__weights': 'uniform'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.5 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                       |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|:----------------------------------------------------------------------|\n",
      "| KNN          |     0.9992 |      0.9992 |   0.9992 |     0.9992 | {'model__n_neighbors': 3, 'model__p': 1, 'model__weights': 'uniform'} |\n",
      "\n",
      "\n",
      "KNN - Test size: 0.8 Results:\n",
      "| Classifier   |   Accuracy |   Precision |   Recall |   F1-Score | Best Parameters                                                        |\n",
      "|:-------------|-----------:|------------:|---------:|-----------:|:-----------------------------------------------------------------------|\n",
      "| KNN          |      0.999 |       0.999 |    0.999 |      0.999 | {'model__n_neighbors': 5, 'model__p': 1, 'model__weights': 'distance'} |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'model__n_neighbors': [3, 5, 7, 10],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__p': [1, 2]  # Minkowski p=1 (Manhattan), p=2 (Euclidean)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning function for KNN\n",
    "def hyperparameter_tuning_knn(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_knn,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Evaluate KNN Classifier\n",
    "partition_results_knn = {}\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    tuned_clf, best_params = hyperparameter_tuning_knn(X_train, y_train)\n",
    "    preds = tuned_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    results = [{\n",
    "        'Classifier': 'KNN',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(report['weighted avg']['precision'], 4),\n",
    "        'Recall': round(report['weighted avg']['recall'], 4),\n",
    "        'F1-Score': round(report['weighted avg']['f1-score'], 4),\n",
    "        'Best Parameters': best_params\n",
    "    }]\n",
    "\n",
    "    partition_results_knn[f\"KNN - Test size: {test_size}\"] = pd.DataFrame(results)\n",
    "\n",
    "# Display KNN results\n",
    "for partition, df in partition_results_knn.items():\n",
    "    print(f\"{partition} Results:\")\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42a296af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted table saved to /Users/maissanafisa/Desktop/Classifier_Performance_Pivoted.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example summary data\n",
    "summary_data = {\n",
    "    'Classifier': [\n",
    "        'Random Forest', 'Random Forest', 'Random Forest',\n",
    "        'Logistic Regression', 'Logistic Regression', 'Logistic Regression',\n",
    "        'SVM', 'SVM', 'SVM',\n",
    "        'Naive Bayes', 'Naive Bayes', 'Naive Bayes',\n",
    "        'KNN', 'KNN', 'KNN'\n",
    "    ] * 4,  # Repeat for 4 datasets\n",
    "    'Dataset': [\n",
    "        'Graduation Prediction', 'Graduation Prediction', 'Graduation Prediction',\n",
    "        'Graduation Prediction', 'Graduation Prediction', 'Graduation Prediction',\n",
    "        'Graduation Prediction', 'Graduation Prediction', 'Graduation Prediction',\n",
    "        'Graduation Prediction', 'Graduation Prediction', 'Graduation Prediction',\n",
    "        'Graduation Prediction', 'Graduation Prediction', 'Graduation Prediction',\n",
    "        'Online Shopper Behavior', 'Online Shopper Behavior', 'Online Shopper Behavior',\n",
    "        'Online Shopper Behavior', 'Online Shopper Behavior', 'Online Shopper Behavior',\n",
    "        'Online Shopper Behavior', 'Online Shopper Behavior', 'Online Shopper Behavior',\n",
    "        'Online Shopper Behavior', 'Online Shopper Behavior', 'Online Shopper Behavior',\n",
    "        'Online Shopper Behavior', 'Online Shopper Behavior', 'Online Shopper Behavior',\n",
    "        'Maternal Health Risk', 'Maternal Health Risk', 'Maternal Health Risk',\n",
    "        'Maternal Health Risk', 'Maternal Health Risk', 'Maternal Health Risk',\n",
    "        'Maternal Health Risk', 'Maternal Health Risk', 'Maternal Health Risk',\n",
    "        'Maternal Health Risk', 'Maternal Health Risk', 'Maternal Health Risk',\n",
    "        'Maternal Health Risk', 'Maternal Health Risk', 'Maternal Health Risk',\n",
    "        'Machine Failure Prediction', 'Machine Failure Prediction', 'Machine Failure Prediction',\n",
    "        'Machine Failure Prediction', 'Machine Failure Prediction', 'Machine Failure Prediction',\n",
    "        'Machine Failure Prediction', 'Machine Failure Prediction', 'Machine Failure Prediction',\n",
    "        'Machine Failure Prediction', 'Machine Failure Prediction', 'Machine Failure Prediction',\n",
    "        'Machine Failure Prediction', 'Machine Failure Prediction', 'Machine Failure Prediction'\n",
    "    ],\n",
    "    'Train-Test Split': [\n",
    "        '20/80', '50/50', '80/20',\n",
    "        '20/80', '50/50', '80/20',\n",
    "        '20/80', '50/50', '80/20',\n",
    "        '20/80', '50/50', '80/20',\n",
    "        '20/80', '50/50', '80/20'\n",
    "    ] * 4,  # Repeat for 4 datasets\n",
    "    'Accuracy': [\n",
    "        0.774, 0.7685, 0.7599,\n",
    "        0.7627, 0.7654, 0.7523,\n",
    "        0.7537, 0.7654, 0.7494,\n",
    "        0.6599, 0.6759, 0.6853,\n",
    "        0.7175, 0.7129, 0.6912,\n",
    "        0.8994, 0.9019, 0.9014,\n",
    "        0.8832, 0.8822, 0.8838,\n",
    "        0.8844, 0.89, 0.8852,\n",
    "        0.8439, 0.8503, 0.843,\n",
    "        0.8783, 0.8775, 0.8722,\n",
    "        0.8621, 0.7633, 0.7241,\n",
    "        0.665, 0.641, 0.6121,\n",
    "        0.7389, 0.6765, 0.6367,\n",
    "        0.6158, 0.6095, 0.5911,\n",
    "        0.8079, 0.7712, 0.6601,\n",
    "        0.999, 0.9992, 0.999,\n",
    "        0.998, 0.996, 0.9961,\n",
    "        0.999, 0.9992, 0.999,\n",
    "        0.999, 0.9992, 0.999,\n",
    "        0.998, 0.996, 0.9961\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Pivot the table to organize by classifier and test partitions\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['Classifier', 'Dataset'], \n",
    "    columns='Train-Test Split', \n",
    "    values='Accuracy'\n",
    ").reset_index()\n",
    "\n",
    "# Save or display the pivoted DataFrame\n",
    "output_path = \"/Users/maissanafisa/Desktop/Classifier_Performance_Pivoted.csv\"\n",
    "pivot_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Pivoted table saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec334d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401a578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
